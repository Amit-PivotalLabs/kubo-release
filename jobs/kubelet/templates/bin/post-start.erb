#!/bin/bash -e

[ -z "$DEBUG" ] || set -x

kubectl="/var/vcap/packages/kubernetes/bin/kubectl --kubeconfig=/var/vcap/jobs/kubeconfig/config/kubeconfig"
node_name=<%= spec.ip %>

# Deleting docker0 route as a workaround to a routing conflict
# between the docker0 bridge and the CNI interface
# TODO: remove this once an upstream docker release is available,
#       which removes or overrides the docker bridge IP
#       See: https://github.com/cloudfoundry-community/docker-boshrelease/pull/82
#
docker0_addr=$(route -n | grep docker0 | awk '{print $1}')
docker0_gw=$(route -n | grep docker0 | awk '{print $2}')
docker0_netmask=$(route -n | grep docker0 | awk '{print $3}')
if [ "${docker0_addr}" != "" ]
then
  route del -net $docker0_addr gw $docker0_gw netmask $docker0_netmask dev docker0
fi

DOCKER_SOCKET=unix:///var/vcap/sys/run/docker/docker.sock
CONTAINER_IMAGE_DIR=/var/vcap/packages/kubernetes/container-images

load_container() {
    path=$1

    echo "loading cached container: ${path}"
    sudo /var/vcap/jobs/kubelet/packages/docker/bin/docker -H ${DOCKER_SOCKET} load < ${path}
}

load_cached_containers() {
    for img in ${CONTAINER_IMAGE_DIR}/*.tgz; do
        load_container ${img}
    done
}

load_cached_containers

TIMEOUT=120


export HTTP_PROXY=10.0.252.2:8888
export http_proxy=10.0.252.2:8888
export HTTPS_PROXY=10.0.252.2:8888
export https_proxy=10.0.252.2:8888

export no_proxy='10.200.0.0,10.200.0.1,10.200.0.2,10.200.0.3,10.200.0.4,10.200.0.5,10.200.0.6,10.200.0.7,10.200.0.8,10.200.0.9,10.200.0.10,10.200.0.11,10.200.0.12,10.200.0.13,10.200.0.14,10.200.0.15,10.200.0.16,10.200.0.17,10.200.0.18,10.200.0.19,10.200.0.20,10.200.0.21,10.200.0.22,10.200.0.23,10.200.0.24,10.200.0.25,10.200.0.26,10.200.0.27,10.200.0.28,10.200.0.29,10.200.0.30,10.200.0.31,10.200.0.32,10.200.0.33,10.200.0.34,10.200.0.35,10.200.0.36,10.200.0.37,10.200.0.38,10.200.0.39,10.200.0.40,10.200.0.41,10.200.0.42,10.200.0.43,10.200.0.44,10.200.0.45,10.200.0.46,10.200.0.47,10.200.0.48,10.200.0.49,10.200.0.50,10.200.0.51,10.200.0.52,10.200.0.53,10.200.0.54,10.200.0.55,10.200.0.56,10.200.0.57,10.200.0.58,10.200.0.59,10.200.0.60,10.200.0.61,10.200.0.62,10.200.0.63' 
export NO_PROXY='10.200.0.0,10.200.0.1,10.200.0.2,10.200.0.3,10.200.0.4,10.200.0.5,10.200.0.6,10.200.0.7,10.200.0.8,10.200.0.9,10.200.0.10,10.200.0.11,10.200.0.12,10.200.0.13,10.200.0.14,10.200.0.15,10.200.0.16,10.200.0.17,10.200.0.18,10.200.0.19,10.200.0.20,10.200.0.21,10.200.0.22,10.200.0.23,10.200.0.24,10.200.0.25,10.200.0.26,10.200.0.27,10.200.0.28,10.200.0.29,10.200.0.30,10.200.0.31,10.200.0.32,10.200.0.33,10.200.0.34,10.200.0.35,10.200.0.36,10.200.0.37,10.200.0.38,10.200.0.39,10.200.0.40,10.200.0.41,10.200.0.42,10.200.0.43,10.200.0.44,10.200.0.45,10.200.0.46,10.200.0.47,10.200.0.48,10.200.0.49,10.200.0.50,10.200.0.51,10.200.0.52,10.200.0.53,10.200.0.54,10.200.0.55,10.200.0.56,10.200.0.57,10.200.0.58,10.200.0.59,10.200.0.60,10.200.0.61,10.200.0.62,10.200.0.63'




if timeout "$TIMEOUT" /var/vcap/jobs/kubelet/bin/ensure_kubelet_up_and_running
then
  ${kubectl} uncordon ${node_name}
  ${kubectl} get nodes ${node_name} | grep -e ' Ready '
  echo "kubelet post-start checks succeeded"
else
  echo "kubelet failed post-start checks after $TIMEOUT seconds"
  exit 1
fi
